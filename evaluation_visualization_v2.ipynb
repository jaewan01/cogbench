{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7c59f5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "db1fbed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cur_task = \"ProbabilisticReasoning\"\n",
    "# cur_task = \"HorizonTask\"\n",
    "cur_task = \"RestlessBandit\"\n",
    "# cur_task = \"InstrumentalLearning\"\n",
    "# cur_task = \"TwoStepTask\"\n",
    "# cur_task = \"TemporalDiscounting\"\n",
    "\n",
    "# model = \"Llama-3.1-8B-Instruct\"\n",
    "model = \"Qwen3-0.6B\"\n",
    "# model = \"Qwen3-32B\"\n",
    "# model = \"gemma-2-9b-it\"\n",
    "str_strs = [0.0, 0.25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7d253685",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dir = \"Experiments/\" + cur_task + \"/\"\n",
    "score_csv = res_dir + \"scores_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b0033926",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "\n",
    "with open(score_csv, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    columns = lines[0].strip().split(\",\")\n",
    "    lines = lines[1:]\n",
    "    lines = [line.strip().split(\",\") for line in lines]\n",
    "    for line in lines:\n",
    "        if \"str_\" not in line[0]:\n",
    "            continue\n",
    "        if model not in line[0]:\n",
    "            continue\n",
    "        steer_str, llm = line[0].split(\"+\")\n",
    "        if steer_str == \"str_none\":\n",
    "            str_type = \"none\"\n",
    "            str_str = 0.0\n",
    "        else:\n",
    "            str_type, str_str = steer_str.split(\"_\")[1:]\n",
    "            str_str = float(str_str)\n",
    "        if str_type not in results:\n",
    "            results[str_type] = {}\n",
    "        results[str_type][str_str] = {}\n",
    "        for i in range(1, len(columns)):\n",
    "            if columns[i] not in results[str_type][str_str]:\n",
    "                results[str_type][str_str][columns[i]] = []\n",
    "            if len(line[i]) == 0:\n",
    "                results[str_type][str_str][columns[i]].append('0.0')\n",
    "            else:\n",
    "                results[str_type][str_str][columns[i]].append(line[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6c7e0c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.25: {'run': ['9'], 'performance_score1': ['51.38024390243903'], 'performance_score1_name': ['rewards mean'], 'behaviour_score1': ['0.6891682926829269'], 'behaviour_score1_name': ['meta-cognitive sensitivity'], 'behaviour_score2': ['0.99'], 'behaviour_score2_name': ['confidence mean'], 'performance_score2': ['0.6829268292682927'], 'performance_score2_name': ['mean accuracy'], 'behaviour_score3': ['0.6891682926829269'], 'behaviour_score3_name': ['adjusted qsr']}}\n"
     ]
    }
   ],
   "source": [
    "print(results['random 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "48134765",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(results.keys())\n",
    "for key in keys:\n",
    "    for str_str in results[key]:\n",
    "        for metric in results[key][str_str]:\n",
    "            if metric == \"run\" or \"_name\" in metric:\n",
    "                continue\n",
    "            results[key][str_str][metric] = np.array(results[key][str_str][metric], dtype=float)\n",
    "            results[key][str_str][metric] = np.mean(results[key][str_str][metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "53dfc2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.25: {'run': ['9'], 'performance_score1': 51.38024390243903, 'performance_score1_name': ['rewards mean'], 'behaviour_score1': 0.6891682926829269, 'behaviour_score1_name': ['meta-cognitive sensitivity'], 'behaviour_score2': 0.99, 'behaviour_score2_name': ['confidence mean'], 'performance_score2': 0.6829268292682927, 'performance_score2_name': ['mean accuracy'], 'behaviour_score3': 0.6891682926829269, 'behaviour_score3_name': ['adjusted qsr']}}\n"
     ]
    }
   ],
   "source": [
    "print(results['random 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6479c79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "symptom_names = list(results.keys())\n",
    "for i in range(10):\n",
    "    symptom_names.remove(\"random \"+str(i))\n",
    "symptom_names.remove(\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f74331c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['depressed mood',\n",
       " 'low self-esteem',\n",
       " 'negativity bias',\n",
       " 'guilt',\n",
       " 'risk-aversion',\n",
       " 'self-destruction',\n",
       " 'manic mood',\n",
       " 'grandiosity',\n",
       " 'positivity bias',\n",
       " 'lack of remorse',\n",
       " 'risk-seeking',\n",
       " 'hostility']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symptom_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "721fd6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_full = list(results[symptom_names[0]][str_strs[1]].keys())\n",
    "metrics = []\n",
    "for metric in metrics_full:\n",
    "    if metric.endswith(\"_name\"):\n",
    "        metrics.append(metric[:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "664ab650",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_symptoms = len(symptom_names)\n",
    "cols = 3\n",
    "rows = (n_symptoms + 2) // cols\n",
    "if rows == 0:\n",
    "    rows = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "12ae0e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in metrics:\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(15, 3 * rows))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # plt.title('Good Scores on SocialChemistry101')\n",
    "    max_val = None\n",
    "    min_val = None\n",
    "    for idx, symptom in enumerate(symptom_names):\n",
    "        vals = []\n",
    "        for str_str in str_strs:\n",
    "            if str_str == 0.0:\n",
    "                vals.append(results['none'][str_str][metric])\n",
    "            else:\n",
    "                vals.append(results[symptom][str_str][metric])\n",
    "        axes[idx].plot(str_strs, vals, marker='o', label=symptom, color='blue')\n",
    "\n",
    "        cur_max = max(vals)\n",
    "        cur_min = min(vals)\n",
    "\n",
    "        if max_val is None:\n",
    "            max_val = cur_max\n",
    "        else:\n",
    "            max_val = max(max_val, cur_max)\n",
    "        if min_val is None:\n",
    "            min_val = cur_min\n",
    "        else:\n",
    "            min_val = min(min_val, cur_min)\n",
    "\n",
    "        # vals = []\n",
    "        # for str_str in str_strs:\n",
    "        #     if str_str == 0.0:\n",
    "        #         vals.append(results['none'][str_str][metric])\n",
    "        #     else:\n",
    "        #         vals.append(results[symptom][-str_str][metric])\n",
    "        # axes[idx].plot(str_strs, vals, marker='o', linestyle='--', label=symptom + \" Negative\", color='red')\n",
    "\n",
    "        # cur_max = max(vals)\n",
    "        # cur_min = min(vals)\n",
    "        # max_val = max(max_val, cur_max)\n",
    "        # min_val = min(min_val, cur_min)\n",
    "\n",
    "        random_values = []\n",
    "        for i in range(10):\n",
    "            cur_vals = []\n",
    "            for str_str in str_strs:\n",
    "                if str_str == 0.0:\n",
    "                    cur_vals.append(results['none'][str_str][metric])\n",
    "                else:\n",
    "                    cur_vals.append(results[\"random \"+str(i)][str_str][metric])\n",
    "            random_values.append(cur_vals)\n",
    "        random_values = np.array(random_values)\n",
    "        random_mean = np.mean(random_values, axis=0)\n",
    "        lower_bound = np.mean(random_values, axis=0) - stats.sem(random_values, axis=0)\n",
    "        sem = stats.sem(random_values)\n",
    "        ci = stats.t.ppf(0.95, len(random_values) - 1) * sem\n",
    "        lower_bound = random_mean - ci\n",
    "        upper_bound = random_mean + ci\n",
    "        axes[idx].plot(str_strs, random_mean, marker='o', linestyle='--', label='Random', color='orange')\n",
    "        axes[idx].fill_between(str_strs, lower_bound, upper_bound, color='orange', alpha=0.3, label='Random Â±95% CI')\n",
    "\n",
    "        axes[idx].set_title(symptom, fontsize=12, fontweight='bold')\n",
    "        axes[idx].set_xlabel('Intensity')\n",
    "        axes[idx].set_ylabel('Score')\n",
    "\n",
    "    for i in range(len(symptom_names)):\n",
    "        lower_bound = min_val - abs(min_val) * 0.05\n",
    "        upper_bound = max_val + abs(max_val) * 0.05\n",
    "        axes[i].set_ylim(lower_bound, upper_bound)\n",
    "\n",
    "    for i in range(n_symptoms, len(axes)):\n",
    "        fig.delaxes(axes[i])\n",
    "\n",
    "    fig.suptitle(metric + \" on \"+ cur_task, fontsize=20, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    fig_dir = \"figures/\" + model + cur_task + \"_\"\n",
    "    cur_metric_name = results[\"random 0\"][str_strs[1]][metric + '_name'][0]\n",
    "    if \"/\" in cur_metric_name:\n",
    "        cur_metric_name = cur_metric_name.replace(\"/\", \"_\")\n",
    "    plt.savefig(fig_dir + cur_metric_name + \".png\", dpi=600)\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
